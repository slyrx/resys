大数据的处理流程，数据是有生命周期的。大数据应该从各种数据源里获得原始数据，数据有结构化的、半结构化和非结构化的。结构化就是大家最熟悉的关系型数据，就是可以直接存在数据库里的，容易理解分析，还可以见到半结构化和非结构化的数据，例如图片和视频，这些就更复杂一点。更多见到的是日志数据。日志数据是大数据处理里常见的内容，一般叫半结构化的数据，即经过处理之后就可以变成结构化的数据。接下来就是要从数据源里采集数据，这就涉及了 flume、scribe、kafka、etl工具什么的、sqoop，这些内容，我们把数据采集回来，还要做清洗和处理，和一些预处理的工作；然后把它存到相应的存储介质里面去，或者说数据库里面去；这部分大家比较熟悉的有关系型数据库 Oracle、Mysql; 另外我们还接触到越来越多的非关系型数据库，比如说接下来要给大家介绍的 Mongo、Redis、基于图的数据库，hbase这样的列存储的数据库；大家认为它和我们熟悉的关系型数据库还是很类似的。表结构也是非常严谨的。各种个样的数据库，我们都是把它当成存储的数据介质就可以了，只要知道，数据采集回来，要存到的就是这些东西就可以了；所以大家如果想到这一点的话，我们做数据存储的话，就可以用不同的工具去替代。比方说，之前的项目有可能是存在 hbase 里面的，我如果要是把它换成 Orcale 可以吗？也是可以的，只不过如果要是数据量特别大的话，或许，效果就不太好。从性能上或者是其他的一些角度考量的话，效果就不太好，或者放到 mongo 里怎么样？ 可不可以呢？也可以，放到 mysql 里也可以。放到现在，就要有一个整体的架构，框架师的这种思维。那一部分，并不一定是那么死板，当时老师怎么讲的项目是什么，它就一定得是什么，不见得是这样子，所以接下来拿到存储之后，下一步做计算。应用到一些大数据的计算框架，比较熟悉的是 hadoop, mapreduce, spark。别的像 strom, flink, mahout 这些都是 大数据框架，如果说我们的项目里现在给大家讲的是 spark，如果说以后到公司里的应用不是 spark 怎么半？其实思维也是一样的，具体的比方说环境搭建，具体api的调用操作肯定回不同，你会重新去学习。但是，我们的思维应该还是一样的，知道它做的事情和spark类似。有这个概念就可以了。做了数据计算和数据处理之后，最后，还要放到应用层面去。给到业务系统去做应用，最后还要做bi分析可视化。最后给用户图形页面展示出来。这就是整个数据生命的一个周期。

这两个图，其实是表示了实时处理和离线处理两个系统。
左边是实时的，右边是离线的
实时处理流程是怎么样的？
首先用户那儿有接口，它会做一些网页操作，以服务请求的形式，传到后台，后台会有一个记录。要不是直接记到数据库里，更多是要把它存到日志文件里去，接下来可以用 Flume 这样的工具，做日志采集，采集到之后，一般情况，会用kafka这样的工具，把它做一个处理，然后就相当于建立一个数据总线这样一个管道，就可以把它传入到实时计算框架里面去。这里一般就像是 kafka streaming，用 streaming 程序就可以把它进行一个实时的计算。得到的结果存到相对应的存储介质数据库里面去，然后就可以数据可视化展示出来了。返回来给用户看了，这就是实时处理的一个流程。

大家之前项目更熟悉的是，离线这部分的处理。经典的流程应该是：前边的过程还是一样，把用户的行为发给后台，后台写到日志文件里面。flume 把它采集出来之后，大家想到，接下来，我们先把它存储起来，然后去做清洗，etl 工具这就上了，然后加载把它放到数仓里去，在数仓里，用hive，这样一些工具，把它做一些管理，接下来给到计算框架里。spark 或者 flink。这里边做完计算之后，最后，再存到相应的数据库里面去，最后给用户可视化展示。

接下来，要做什么呢？
要做的是一个推荐系统，我们可能不会涉及到之前那么多的工具，那么多框架性的东西，我们关键是要看，我们得到的东西应该是推荐列表，这里我们主要是要哪些？比方说要实时推荐，应用的是实时处理的流程；然后我们可能还需要一个离线的推荐，另外还需要一个跟统计相关的推荐；所以这里的推荐是基于隐语义模型做预测评分的推荐，结合后面做的统计推荐，都是大数据离线框架。然后可能会想到点每个电影进去会有一个详情页，详情页会有用户行为的收集，比方说这里会点一个评分，收集这个评分数据，下面会想到，还应该记录它的一些标签，然后根据评分有一些相似的推荐，基于内容的推荐，这些就是我们想要去实现的。

接下来，就看看整体需要哪些模块。整体来讲，就是需要这些功能，需要实时推荐个性化推荐，另外需要一个离线的个性化推荐基于隐语义模型做的一个预测评分；另外还需要一个非个性化的统计相关的推荐；另外是相似性推荐，根据用户的点击行为和物品本身的内容信息进行考量。另外还有一些用户行为在业务系统中实现，用户可以评分，可以打标签，还可以做搜索，做模糊查询，这些在业务系统中都应该实现。只不过实现完了之后，会跟后边的数据库和推荐系统进行交互，所以这些也是要了解的。这些内容，如果把它抽象一下，可以抽象成这么几种服务，实时推荐，离线推荐，离线统计，另外还有内容检索。这是我们几大服务的类别；接下来，再去看的话，根据之前推荐方式和推荐方法的划分，可以把它提炼成，我们要用到哪些呢？基于模型的推荐，离线需要隐语义模型，实时推荐也需要自定义的一个模型；所以基于模型的推荐还是很重要的一个部分；另外一个是协同过滤，LFM是基于评分数据；这也算是一个协同过滤的推荐；另外我们会想到，如果我们利用协同过滤；评分数据，去求它电影之间相似度的话；也是基于协同过滤 item-CF 的推荐。所以看到协同过滤也是很重要的一个部分；另外还可以基于内容去做推荐。大家会想到，从电影的信息里提取它们的内容特征，得到特征之后就可以进行相似推荐了。最后还要基于整个电影网站最后得到的结果再写回去，就变成了一个推荐网站。这是我们最终的目标。

接下来，看一看项目整个的系统架构
首先，用户看到的应该是一个可视化的界面，这是我们的网站前端。这个项目是用 angularjs 来写的，这块儿会直接给大家，不用去管
有前端当然就有后台了，用户的数据从前端进来，会发到综合业务后台，这里使用 spring 搭的一个业务后台。后台的数据，除了响应前端的数据处理外，是不是还应该把对应的数据写入到数据库里面去。这个项目核心用到的数据库是 mongo 核心业务数据库,  另外还有一些辅助的数据库，比如说什么呢？可以看到，我们用到了 es；大家想，前面我们不是有一个搜索这样的业务需求吗？所以我们肯定会把一部分内容放到 es，作为我们的搜索服务器。另外还有一部分，会放到 redis 里面；这部分很好理解，就是要做一个缓存；这都是一些常见的系统架构；尽管我们这个项目不是特别的大；但是其实是想把之前讲到的东西给大家综合起来，做一个应用。这是我们基本电影网站的业务系统。
其实是基于这样一个网站，我们要做出推荐这样一个模块。当然跟它会有交互。跟它的交互主要应该在哪里呢？主要应该在数据库这部分做对应的交互。原先的业务数据，都存在了数据库里面。然后我们要从里面读数据，读完去做分析，做计算；得到的推荐结果，还应该写到对应的数据库里面，让我们的后台业务能把它读取出来，然后展示给用户。所以我们最后得到的结果，也是准备要写入到 mongo 里去的。这是整体的业务框架。大家可以看一下，我们整个的推荐模块，大的范围可以分为哪两类呢？可以想到，首先有一个离线统计服务，我们会想到，大家会写 spark sql; 把数据里的一些统计信息找出来，把这部分离线统计做完之后，大家会想到，我们的核心，这部分还是非个性化的，看到的都一样，我们的个性化如果要做一个统计推荐的话，要用到之前说过的隐语义模型去做预测评分。所以还应该有一个离线推荐服务，专门做这样一个预测评分。这一部分要用到什么呢？既然要用到隐语义模型，我们将用到 als ，这部分在那儿找呢？这就涉及到了 spark 里的 MLlib，所以，我们会简单的给大家说一说 MLlib 里边一些算法。从这里边去调用。我们可以用一个 讲过的 azkaban 来做工作调度服务，把这两部离线服务调度起来。可以定时跑这个任务。跑完之后，结果定时更新。因为这部分是离线的么，所以说，当然就可以这么去做。当然在之后实际实践的时候，因为比较简单，跟本身的业务也没什么关系，这部分我们就忽略掉了。大家想做，可以把它加进来。然后大家会想到，得到的结果最后还是写到 mongo 里面去。这就是离线这块儿。大家会想到，除了离线之外，还有实时的推荐，首先从业务后台，或者其他的环境里收集日志，flume 拿到日志，然后会想到给 kafka 做一个消息队列的缓冲。通过这样一个缓冲通道，构建这样一个信息渠道，把它可以给到 spark streaming 去做一个实时推荐。在这里，大家会想到，实时推荐的时候，我们除了实时收集来的行为数据，比如评分数据，之外，还需要什么呢？可能还需要一些之前的相关的数据。大家可能会想到，需要从redis里找些数据，还有可能从 mongo 和 es 里拿数据。最后得到的结果，还是要写回 mongo 里面来。这就是整体的项目框架。可以看到，大概整体分就是这么几大块儿，离线，近线，在线。

下面我们具体化一下：
首先，可视化里，可能回给用户做哪些展示呢？推荐结果展示、电影检索、电影信息展示、电影标签和电影评分，后四个应该是给出的业务系统就实现的。尽管比较复杂，不用管。对应到业务后台，就有各种各样的服务，推荐结果查询服务，查询已存入数据库中的内容，电影检索服务，电影信息查询服务，电影标签服务，电影评分服务，这些服务都是业务已经实现好的。

接下来，大家会想到，数据库有 es， mongo，和 redis，里面都是有内容的。可以想到，正常的业务线来讲，一开始会有一个冷启动的问题，一开始，数据库是空的，所以我们还得有一个漫长的收集数据，然后慢慢的数据增加的一个过程。现在既然是大数据项目，我们默认是有数据的。我们这个项目里，数据是从那儿来呢？我们这里直接用几个文件把它保存好，直接把数据加载到业务数据库和对应到数据库里面来，就可以了。因为大家会想到，如果要是运行了一段时间的业务系统的话，mongo 里肯定是有数据的。所以，我们这里是专门写了一个数据加载服务，做这部分事情，今天下午我们就要把这部分实现，大家会想，这部分，我们会怎么做呢？因为数据量比较大，所以我们还是用到了 spark SQL；大家会想到，到时候我们用一个spark session，会有一个get 方法，把对应的数据结构对应好，跟 mongo 和 es 都有对应的链接方式，你只要定义好的数据，我直接往里面写就可以，所以是这样的一个过程，有了数据之后，就直接把它写到数据库里面，另外 es 里面也要写一部分数据。数据的部分涉及到两个部分，一部分往 mongo 里写数据，一部分往 es 里写数据。写入数据之后，就可以做离线统计服务了，这里可能涉及几个指标，比如说，电影平均评分统计；统计评分的个数统计，代表电影热门程度，看的人多，所以评分就多；最近电影评分个数统计，代表最近的热门程度，类别的top N统计，这都是一些常见的统计量。感兴趣的话，可以把这部分再拓展一下。想一个实际的电商项目里会用到哪些指标，写进去。这部分当然可以用 azkaban 把它调度起来，它的数据当然从 mongo 里面读取，读取出来之后做处理，一个一个都应该有一个推荐列表，最后再写到 mongo 里就可以了。离线这部分，除了统计服务之外， 还有一个离线推荐，这部分，我们主要应用的是隐语义模型，做一个预测评分，这一部分，我们主要想到用ars，同样也可以用 azkaban 把它管理起来。这里我们主要得到的就是用户的推荐电影列表，这个列表也可以写到业务数据库里面去，另外，这个离线服务还有一个副产品，什么副产品呢？大家会想到，我们稍后，还要有个实时推荐，实时推荐，我们大家想，来了一个电影评分，我根据什么去推呢？大家直观的想法，是不是我应该找到跟这个电影评分相似的电影，那这个相似，我如果现场去算的话，那么多电影，我在统计它的那些特征，我跑一遍 ars，再去找它隐藏特征，再去算它相似度，是不是有点儿来不及啊？你这个实时性是不是就差多了，所以大家就想到，那如果说，我电影本身特征相对比较稳定，相对不大的话，我是不是可以提前把它算出来？我就可以提前把电影的相似度算出来，我到时候来了一个评分的时候，是不是结合它之前算好的相似度，就可以找到跟这个电影当前相似的电影啊，就可以做推荐了。这就是我们基本的想法。所以我们这里，离线推荐服务还应该有一个副产品，算出来，电影之间的相似度。 所以我们把这个也写入到对应的mongo 数据库里面去。好，这就是我们离线推荐的部分，大家看好像很复杂，但实际上这么一说的话，也就比较清晰了。接下来想到，这部分有可能还要去做缓存，因为，如果实时推荐快的话，必须做一个缓存。接下来大家就想到，剩下实时的一个推荐部分，实时的流程是什么呢？是不是，用户在用户在这里有一个电影评分的操作，做了一个点击对不对？然后就会把这个请求发到后台来，后台的电影评分服务做一个响应，是不是对应的 就会，首先数据应该写到业务数据库里面，另外是不是还应该有一个日志记录，这个日志就可以用 flumn 去采集，然后是不是就可以给到 kafka 做到消息队列的缓冲，对应的这里面我们能定义什么呢？是不是应该定义一个 filesource 和 kafkaSink，我们这里日志来了之后，就 filesource,通过管道的通道给到 kafkasink 来，kafka 这里面是不是可以定义不同的 topic 再去做一个过滤处理，这个是之前讲过，比方说我们这里就是刚来的这个 topic 叫 log，之后过滤，我们另外再定义成一个 topic，这相当于我们做了日志提取之后，核心算法想要的数据结构了，比方说，这里，我们的数据机构就把它中间用竖杠分割了几个字断，就是这样的一个模式。kafka 做完这样的处理之后，可以把内容给到实时推荐系统。这个算法我们就需要好好的设计一下，考量一下。有了这个实时推荐算法之后，我们再去做一个，我们要想到，这里的数据内容要过来，是不是 redis 里的数据也得过来？也得拿到我们对应想要的东西。最后是不是再把它写回到 mongo 里去。这就是我们整个实时推荐的一个过程，当然，对应的搜索服务就要结合 mongo 和 es了，推荐结果的查询，我们从这里拿数据，返回到前台；电影检索的话，主要就是 es 模糊查询直接可以返回。电影信息展示和对应的标签，肯定是从数据库里拿内容就可以了。这就是我们整个的项目流程。当然了，下一个还有一个数据流。把刚才我讲的内容，又细化了一下，大家如果想看的话，也可以看看。直接一眼看上去好像特别的复杂，特别的乱。但实际上如果我们一部分一部分过下来的话，其实就那点儿东西。就是我们之前讲过的那些东西。就是要用这样一个项目给大家综合起来做一个复习就好了。


————————————————————————

下面一部分是一个数据源的解析，数据源这一部分，大家会看到，前面有一个 dataloader 要把它直接先加载到数据库里去，本身的数据源就是3个csv文件，放在这里给到大家，可以看到从命名上就可以看出，这3个数据分别是什么数据，电影的基本信息，用户的评分信息，用户给电影打上的标签信息。来看一下电影的信息长什么样子，电影信息主要有这么几个字段，共10个，第一个是 id，之后是描述，其中有些内容没有，这在处理时要稍微注意一下，然后时间长度多长，发行时间，拍摄时间，语言，另外是类别，演员，导演，这里有很多信息，大家可以想到，最后跟我们是否给他做推荐相关的 信息可能是那些？不会用id做推荐，电影时间长度会做推荐吗？有可能，但是它的关联度就不大。所以大家会发现，我们最后给大家实现的其实就找了一个跟最后的推荐结果最相关的一个特征，做了特征选取。就是类别，认为认为它和推荐的内容最相关，所以我们以这个为例子，大家可以扩展别的，比如电影描述也有很多关键信息，但是电影描述这里没有；接下来大家看一个评分信息，评分信息就比较简单了，一个用户给一个电影做了一个评分，然后还有一个评分的时间戳，可以看到这个数据是很详尽的，所以大量的工作是围绕评分数据和行为数据来做的，隐语义模型就是基于它来做预测评分。最后做实时推荐的时候，电影的相似度也是基于这个来做的，这是评分做的。还有一个电影标签信息，这和评分数据非常接近，一个用户给一个电影打一个标签，后面还有一个时间戳。接下来要做的就是，从这些数据里面去做推荐，最详实的数据是电影信息评分数据，这部分数据比较重要，所以我们就主要基于这两部分数据。电影信息里最关键的是类别信息，所以基于内容推荐的时候，我们就用类别信息。

接下来，再给大家看一下主要的数据模型，这里已经把表的结构写出来了，大家可以看到，左边的这三个表是不是就是我们基本的数据来源，前面已经讲了，三个文件代表原始数据，把刚才的字段用表保存起来就可以了，另外还涉及到什么样的表呢？会想到业务系统应该有一个用户表，但是这个不用去太关心，只要有 uid 就可以了，做推荐我们如果没有涉及到业务系统里能够收集到的用户信息，如名称，密码，创建时间；如果想要基于这个做用户画像，基本上是不可能的，当然了，我们后面给大家讲做冷启动的时候，业务系统会有一个一开始去点选一个兴趣标签，那是一个冷启动，大家会想到，这个标签是直接和对应的电影类别匹配就可以了，是不是和我们的业务系统都没有关系了，业务系统直接就搞定了, 只要标签匹配，推出来就可以了，所以这部分我们就弱化了。我们关键要实现的推荐，需要有哪些表呢？关键实现的推荐需要写哪些表呢？统计推荐是每一个统计推荐都应该对应有一个表，就是最近电影评分个数统计表，电影平均评分表，电影评分个数统计表，电影类别 top10矩阵。都是统计相关的。然后下面大家会发现，还有一个离线用户统计的结果，这个列表要有一个，另外还要有一个实时推荐的结果，这两个是我们最后的统计里列表，另外还有一个这部分表需要存进去，在做ars计算之后，他会按照预测评分推荐出一个推荐的电影矩阵，另外还有一个副产品电影的相似度，这部分也直接写进去。在 mongo 里主要是这些内容。

接下来，就是挨个介绍模块了
首先介绍统计模块，这块儿分成了四部分，主要的想法是，从业务数据库 mongo 里读出来，读的过程中，就用 sparkSession里的 read方法，读出来就可以了，这里要有一个 mongo和spark的连接器，得有这个工具，我们才能把两者连接起来，使用read函数。这个就是read，大家看看到时候怎么实现就可以。读出来之后，离线统计服务就可以做对应的统计计算了，用sql把它统计出来就可以了，里面主要是这四项，得出来的内容，最后再写回去，点 wirte 方法，最后再写回到 mongo 里面去。就是这么简单。
然后每一项具体来看一下，第一个是历史热门电影统计，大家会想到，我们这个 sql 怎么写呢？怎么统计历史热门呢？什么样的电影叫热门电影呢？我们的数据只有评分数据，所以我们就把评分数量越多的代表越热门，
此处是细致的讲解 4 个 sql 函数。后续是使用了 spark 的一些 sql 算子来进行实现的。

————————————————————————————————
接下来是基于隐语义模型的离线推荐，这里面的核心就是基于 als的算法训练隐语义模型，训练出来的模型之后，就可以把两个特征矩阵，用户特征矩阵和电影特征矩阵，乘回去得到一个预测评分。根据预测评分，它的大小就可以得到用户的推荐矩阵。用户的推荐列表构成的一个矩阵，这就是我们的离线推荐要的内容。当然最后还有一个副产品，为了后面实时做推荐的时候，我们想要拿到电影之间的相似度，所以在这里我们已经拿到了电影的特征矩阵，每个电影的特征向量已知了，我们可以根据这个特征来求出它的相似度。这就是我们离线要做的内容。整个的项目架构里，它就是这一小部分。接下来，大家看一下，als这部分大家怎么去做，其实大家看，非常简单，als 想要做模型训练的话，核心就一行，就这里：
var model = als.train(trainData,rank,terations,lambda)
一行搞定。
阿尔法是什么，梯度下降法的步长。
traindata 怎么得到的呢？基本的评分数据从评分表里 read 出来，转成一个 dataset 然后转成一个 rating 的数据结构。必须是 ALS 要求的 RDD[Rating(uid,mid,score)], 变成这样之后直接传进入，就搞定。可以看到，前面理解的时候难，后面实践很简单。后面还有几个参数，这几个参数怎么样获取呢？可以想到，一开始实现的话，就拍脑袋直接给一个完事儿，就像在python 程序中给一个就可以，但是在实际项目中应该做参数调整，参数调整要做交叉验证，交叉验证是不是得放到划分训练集测试集上面去做测试，用什么指标来衡量呢？可以看到用rmse来衡量。这个值越小，对应的参数越好。到时候，给一组参数，选一个均方根误差最小的参数，作为经典参数。
当然，模型的参数选择评估的过程，我们提到后面如果要做推荐列表的话，是不是其实是不是一个分类问题啊？评估的时候是不是要用到，精确率，召回率相关的一些参数，我们这个项目没有涉及，要想评价精确率和召回率，还得收集用户反馈数据。这个就比较复杂了，这里没有涉及。大家要知道，推荐系统最后你推荐出来的列表要去评价的话，还得用到这些。
前面是拿到了训练的模型，模型出来之后，还没有拿到推荐列表呀；怎么样得到用户的推荐列表呢？想到我们要先做一个预测评分，预测评分怎么算？其实也很简单，就 model.predict(userMovies) , predict 传什么参数呢？有讲究，必须得传一个 uid mid 元组类型的 rdd，这就是每一个用户对应每一个电影，他要有一个空矩阵传进去，空矩阵怎么算的？这里直接用每一个user和没一个movie做笛卡尔积，相当于两个集合 join，而且是一对一，它是一个全外连接，空矩阵传进去，然后把它传进去，就可以得到预测评分，然后 groupbykey，对应的uid选出来，把所有预测出来的电影的评分都 groupby，做一个聚合，再得到一个评分都列表，列表里再去做一个排序，再读取里面的前多少个。就得到我们最后想要的用户推荐列表，是一个 RDD。一个用户对应一个 列表 seq。seq里面是一个电影对应一个评分。再把对应得到的结果写回到 mongo 里。这是离线推荐的结果。

除了这个结果，还要一个副产品，所有电影的相似度，算相似度根据什么去算？可以根据类别计算相似度，但那个是不是就相当于基于内容去做推荐了，现在是基于行为数据，还是基于评分数据的，基于评分数据，怎么拿到电影的特征呢？基于内容想到从分类信息里拿到的，要先提取特征，找相似度，那这里面如果要能从评分数据提取出电影的特征的话，也可以算相似度，电影的特征向量怎么算？模型分解出来是什么东西？模型训练完就得到一个p，一个q，p和q是什么？用户特征矩阵和电影特征矩阵，那电影特征是不是训练完成就得到了？是不是直接从得到的q里就可以算相似度了？所以这就是一个基本的思路。
对于我们的算法而言，model.productfeaures 这就是model里定义好的一个属性，代表商品的特征，所以 model训练好以后，大家会想到，应该有一个userfeatures 和 productfeatures，我们要的是 productfeatures ，得到这个电影的特征，我们要一个电影的相似度，那么是不是要把两两的相似度都做一个计算啊，跟前面有类似的地方就是说，要把每一个电影和每一个电影做一个匹配，好像是做一个全外连接，是不是还可以把它算一个笛卡尔积，得到的结果就相当于是每一个电影和每一个电影对应上作为一个元素，特征向量都已经知道了，根据余弦相似度，求相似度，这个余弦值就可以作为相似度存储起来，为什么不算欧式距离，要算余弦相似度？现在用的是评分数据，用户给电影的评分它有可能出现一个什么状况呢？有可能每一个用户给电影评分的时候，有可能并不是这两个电影本身差别比较大，而是因为我这个用户就是评价比较苛刻，我给所有电影评分都比较低，我给3分相当于就是非常好的好评了，大部分是1分，2分，另外一个用户呢，比较宽松，大部分电影都能得到3分，然后她的好评就是5分，那大家可以想到，如果有部电影用户，前一个用户给他的评分是3，后一个评分是5分，大家会想到，这两个评分差距其实没有我们想象那么大，那同样，一个用户给两个电影的评分，一个是1，一个是3，那另外一个用户给这两个电影的评分，一个是3，一个是1，那这两个向量其实差距很大，怎么样表达方向上面的差距呢，是不是用夹角更好？所以就用了夹角的余弦值，那为什么用余弦值呢？因为向量就是这么求的，两个向量做点击的公式里，直接使用它两的模长乘积乘以余弦算出来的，算点积比较好算，反过来求余弦比较好求。接下来要做的计算就是计算余弦相似度，把它保存到列表里。这就是这样一个过程。

接下来，大家可以看到整体的流程， 算出来的内容，一部分要存到 mongo 里，这是我们的评分矩阵，一部分实时推荐系统要从缓存里拿的话，还要把它存到 redis 里面。当然，这一部分如果对速度要求不那么高的话，全部存到 mongo 里也是可以的。实际应用就不那么复杂了，直接把它放到mongo里面。

接下来，还有最后一部分就是重要的实时推荐模块。我们来看一下，实时推荐模块是整个框架的这一小块儿，首先来看一下它的这个架构，主要出于什么样的考虑，大家会想到，既然是实时推荐，要求就是要速度快，基于这样的要求，你需要速度快的结果，就是结果可以不那么精确，既要速度快，还要特别精确，这要求太高了，如果两个都能达到，那么就根本不需要离线推荐了，这个推荐什么都好，什么都能做到了，所以，我们的想法是，速度要快，结果可以不特别精确。所以我们是不是就可以按照前面，提前把相似度算好，不需要实时去更新，然后我们还要有一个预先设计好的模型，根据这个模型，也就是我们预定的规则，然后又有了现成的相似度，然后我们直接一算，就把它算出来了，这样就很快。这就是我们基本的一个想法。而且我们会想到，这里我们要做的计算就应该只是针对当前这个用户这次评分，相关的一些计算，不要计算所有的，那肯定计算量就很大了，
所以我们的整体流程就是，来的数据就是一个用户评分数据，四项，收集到日志里面来，还是要过 flume 然后 kafka ，最后输入到 spark streaming 实时推荐算法来，streaming 实时推荐算法还是要用到 redis 里面的数据的，最后的结果写回到 mongo 里去。
这就是整体的一个架构。

具体我们怎么样去做实时推荐，他的模型去做定义呢？这里面先把这个列出来，大家先想如果让你去设计这个模型，你怎么设计？看起来很复杂是不是？我们先把它简化一下，我们已经拿到的数据是什么？我们先梳理一下这个思路，已经拿到的数据是，当前有一个评分数据，刚给一个电影做了一个评分，然后我们是不是拿到了所有相似度的矩阵？也就是说，和它相似的电影都能拿出来，那大家可以想到，我基本的一个想法那不就是相当于 item cf对吧，你既然看了这个电影，对这个电影感兴趣，我把跟这个电影相似的全选出来，推荐给你，那不就完事了？大家会觉得这个推荐会有什么问题吗？可能有问题，会有什么问题呢？这种推荐的问题在于，我看了一部电影，确实代表对这个电影还是感兴趣的 ，但是我对他是有评分的啊，我如果给他一个好评，一个5分，那这部电影很赞，我对它又感兴趣，又有好评，跟它相类似的出来，这个没毛病，假如我给他一个1星差评呢？尽管对他有点儿兴趣看了，最后是一个差评，你真的确定要给我推荐跟它类似的东西吗？所以大家会想到，在这种情况下，我们是不是还应该综合把这个评分也考量进去？因为评分其实是一个很特殊的数据，它代表什么呢？代表，评分是不是代表用户的一些兴趣？你对他不感兴趣，你不会，看它，买它，不会对他有评论，本质是代表有一定兴趣的，是本身评分的高低，更加强烈的表达了用户的偏好，它代表了用户到底喜不喜欢这个东西？所以这两部分内容我们是要综合考虑的，而且更重要的，我们应该把这个评分综合考虑进去，那怎么样把评分综合进去？那是不是应该把评分和相似度做一个加权？是不是应该有一个权重值？和一个电影，比方说拿到了跟它类似的电影，如果本身这个电影评分很低，那是不是你跟它很接近，但是这个接近其实用处不那么大，如果是1分差评，和它很接近，我对你的推荐力度也没有那么大，大家可能就会想到，那你对什么样的推荐力度大呢？当然就是有好评的电影才行，所以我们现在要综合考虑，不能考虑1次评分了，可能要综合考虑最近的k次评分，这样就可以避免，只有一次评分，如果是差评，推荐出来值得推荐的东西很少。所以综合考虑，最近的k次评分，把他们都拿出来做一个加权计算。如果要是高分电影，对应的相似度权重大，差评低分的电影权重小，得到的最后加权求和的结果，就是我得到的一个推荐的优先级。这是一个综合的考量。看一下，最后的过程是怎么做的？先获得一组备选电影，备选电影从那儿选？就从相似的电影中去拿，相似的电影也有用，你看这部电影评分了，对这个电影相关的东西感兴趣，所以，直接拿出来电影作为备选电影，具体怎么做呢？把每一个备选电影，单独去做计算一个推荐优先级，比方说现在，对这个备选电影，要算一个优先级，它的推荐优先级怎么算？综合考虑最近的k次评分，跟k评分过的电影，一个一个做相似度的评价。算它的相似度。跟它相似度最后在它的评分做一个加权求和，它代表了对x的一个推荐程度。这到底是一个什么思维？就是说，我这里有一组已经评分过的电影，你现在它是备选，我对他到底推荐力度有多强，你挨个跟我已经评价过的电影比较，到底有多相似，很相似，而且评分又很高，那是不是这个得分就很高？所以这两项一乘，得分就高，这里面我们的公式是不是要把它的相似度和评分，评过电影的评分一比，跟它的相似度很高，但是评分很低，那是不是最后的评分也会比较低，所以这个就没什么用。所以我要选择的就是说，你跟高分电影相似度很高的 电影，它最后的推荐力度就会很高，所以我们把最后的加权做一个求和。再除以 sim_sum ，所有的个数，相当于求了一个加权平均数，把前面这一项作为推荐优先级计算的一个基本项，这是我们核心的推荐优先级。除了这个推荐优先级之外，后面我们还加两项，加奖励，减惩罚，对什么做奖励？对什么做惩罚？假如我这一列评分全是1分差评，那是不是我这次算出来的推荐优先级综合来看，就应该整体降低，因为你都是差评，你这个推荐出来效果，肯定不会太好，所以大家会想到，我这里还要，如果都是好评的话，我的推荐力度整体增强。这里incount表示，所有最近k次评分里面高分的个数，自己可以定义什么是高分，如果小于3，应该是一个低分，做一个衰减。应该做一个惩罚，前面的lg是表示衰减程度，不要那么剧烈。前面好不容易算出来一个优先级，就几分，你后边评价的个数一多，20几分，直接加一个20，这个显然不好，所以我们做一个log的衰减，即使无限增大，也是有上限的。那么大家看下计算的公式，怎么样算呢？比如说x的推荐优先级，推荐度，推荐评分怎么算？就是让他跟所有已经评分过的数据，依次算相似度，a 算一个相似度，叫 sim(A,x) ,积a的评分5。对b也要这么算一下，对c也要算，算完了，除以个数，除以3. 做了一个加权平均，这里没有算d，想把d算一遍也可以。

因为d和它的关联，在备选电影中已经选出来了，备选电影都是和d相关的，如果想加进来，也是一样的。然后后边高分项，是不是是要看4和5两项，所以加上 log 2，减去 log 1 一项。防止是0，求一个跟1 的max。所以是这样的一个值，这就是实时推荐部分的一个计算。最后是怎么样得到它的推荐列表呢？其实也很简单， 首先拿到的是相似度矩阵里拿到候选电影，然后redis里应该有最近的k次评分，这应该是提前写好的，拿到最近的k次评分，接下来要做的就是对每一个候选电影 要计算它的推荐评分 ，怎么算？就是候选电影和k次评分的电影算相似度，然后做加权平均算基础分数，然后再加上高分有几个低分有几个，加两个偏移项，最后得到的结果就是当前候选电影的评分数。最后得到一组评分一个列表，根据这个列表和之前实时推荐的结果做加权的合并，根据高低做一个合并，合并之后，得到的是实时推荐列表。写到mongo里就可以。这就是实时推荐这部分。下来之后，还得再好好梳理梳理，把过程想清楚，接下来，写代码的时候就会简单一些。

最后，还有一部分基于内容的推荐，这里就简单说了，数据最关键就是电影的标签，这里就基于标签做一个推荐就好，这就类似于，item cf，基于电影标签算出特征向量就可以算相似度了， 把电影的相似度矩阵说出来之后，还是放到实时推荐的模块里，照样推出就可以。这个方式一样。简单的实现，最后的实现相当于分区混合，不同模块，推荐的内容，在页面不同位置实现，实际项目不会这样写，实际项目写清用途，人们可以理解的题目实现，
